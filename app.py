import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
import os
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score, f1_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.cluster import KMeans
from datetime import datetime, timedelta
import plotly.figure_factory as ff

# Configura√ß√µes do Streamlit
st.set_page_config(
    page_title="InfiniteBus - ClickBus",
    page_icon="üöå",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Configura√ß√µes para os plots
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)

FILEPATH = "df_t.xlsx"  # Caminho fixo

def load_and_preprocess_data(filepath):
    """Carrega e pr√©-processa os dados da planilha."""
    try:
        if filepath.endswith('.csv'):
            df = pd.read_csv(filepath)
        elif filepath.endswith(('.xls', '.xlsx')):
            df = pd.read_excel(filepath)
        else:
            st.error("Formato de arquivo n√£o suportado. Use .csv ou .xlsx")
            return None
        st.success(f"Dados carregados com sucesso: {df.shape[0]} linhas, {df.shape[1]} colunas.")
        # Convers√£o de colunas importantes
        df['date_purchase'] = pd.to_datetime(df['date_purchase'], errors='coerce')
        n_invalid_dates = df['date_purchase'].isna().sum()
        if n_invalid_dates > 0:
            st.warning(f"{n_invalid_dates} linhas possuem data de compra inv√°lida e foram convertidas para nulo (NaT).")
        df['time_purchase_hour'] = pd.to_datetime(df['time_purchase'], format='%H:%M:%S', errors='coerce').dt.hour
        numeric_cols = ['gmv_success', 'total_tickets_quantity_success']
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # Criar colunas √∫teis para an√°lise temporal
        df['purchase_year_month'] = df['date_purchase'].dt.to_period('M')
        df['purchase_day_of_week'] = df['date_purchase'].dt.day_name()
        df['purchase_month'] = df['date_purchase'].dt.month_name()
        df['purchase_year'] = df['date_purchase'].dt.year
        df['purchase_day'] = df['date_purchase'].dt.day
        
        # Criar outras colunas √∫teis
        df['avg_ticket_price'] = np.where(df['total_tickets_quantity_success'] > 0, 
                                        df['gmv_success'] / df['total_tickets_quantity_success'], 
                                        0)
        
        # Identificar viagens com retorno
        if 'place_origin_return' in df.columns and 'place_destination_return' in df.columns:
            df['has_return'] = (~df['place_origin_return'].isna()) & (df['place_origin_return'] != '0')
        
        return df
    except Exception as e:
        st.error(f"Erro ao carregar os dados: {str(e)}")
        return None

def find_column(df, possible_names):
    """Procura uma coluna no DataFrame, tolerando pequenas varia√ß√µes de nome."""
    cols = [c.lower().replace(' ', '').replace('_', '') for c in df.columns]
    for name in possible_names:
        name_clean = name.lower().replace(' ', '').replace('_', '')
        for i, col in enumerate(cols):
            if name_clean in col or col in name_clean:
                return df.columns[i]
    return None

def calculate_rfm(df):
    """Calcula as m√©tricas RFM (Rec√™ncia, Frequ√™ncia, Monet√°rio) por cliente."""
    rfm = df.groupby('fk_contact').agg({
        'date_purchase': lambda x: (pd.Timestamp.now() - x.max()).days,  # Rec√™ncia
        'nk_ota_localizer_id': 'count',  # Frequ√™ncia
        'gmv_success': 'sum'  # Monet√°rio
    }).rename(columns={
        'date_purchase': 'recency',
        'nk_ota_localizer_id': 'frequency',
        'gmv_success': 'monetary'
    })
    return rfm

def parte1_analise(df, tickets_col):
    """InfiniteBus: Mapeamento Comportamental e Segmenta√ß√£o Din√¢mica do Cliente."""
    
    # Criar tabs para diferentes an√°lises alinhadas com o InfiniteBus
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üìä Vis√£o Geral", 
        "üë• Mapeamento Comportamental", 
        "üîÑ Proje√ß√£o de Ciclo de Compra",
        "üó∫Ô∏è Previs√£o de Destinos",
        "üéØ Recomenda√ß√µes"
    ])
    
    with tab1:
        st.header("Vis√£o Geral do Neg√≥cio")
        
        # Row 1: KPIs principais
        col1, col2, col3, col4 = st.columns(4)
        
        total_gmv = df['gmv_success'].sum()
        total_tickets = df[tickets_col].sum()
        num_transactions = df['nk_ota_localizer_id'].nunique()
        num_customers = df['fk_contact'].nunique()
        
        with col1:
            st.metric("GMV Total", f"R$ {total_gmv:,.2f}")
        with col2:
            st.metric("Total de Passagens", f"{total_tickets:,.0f}")
        with col3:
            st.metric("Transa√ß√µes √önicas", f"{num_transactions:,.0f}")
        with col4:
            st.metric("Clientes √önicos", f"{num_customers:,.0f}")
        
        # Row 2: M√©tricas derivadas
        col1, col2, col3, col4 = st.columns(4)
        
        avg_gmv = total_gmv / num_transactions if num_transactions > 0 else 0
        avg_tickets = total_tickets / num_transactions if num_transactions > 0 else 0
        avg_ticket_price = total_gmv / total_tickets if total_tickets > 0 else 0
        avg_customer_value = total_gmv / num_customers if num_customers > 0 else 0
        
        with col1:
            st.metric("GMV M√©dio por Transa√ß√£o", f"R$ {avg_gmv:,.2f}")
        with col2:
            st.metric("Passagens por Transa√ß√£o", f"{avg_tickets:,.2f}")
        with col3:
            st.metric("Ticket M√©dio por Passagem", f"R$ {avg_ticket_price:,.2f}")
        with col4:
            st.metric("Valor por Cliente", f"R$ {avg_customer_value:,.2f}")
        
        # An√°lise Temporal
        st.subheader("An√°lise Temporal de Vendas")
        
        # GMV Mensal com linha de tend√™ncia
        st.write("### GMV Mensal")
        sales_by_month_year = df.groupby('purchase_year_month')['gmv_success'].sum().reset_index()
        sales_by_month_year['purchase_year_month'] = sales_by_month_year['purchase_year_month'].astype(str)
        
        # Adicionar linha de tend√™ncia
        fig = px.line(sales_by_month_year, 
                    x='purchase_year_month', 
                    y='gmv_success',
                    title='Evolu√ß√£o do GMV Mensal',
                    labels={'gmv_success': 'GMV (R$)', 'purchase_year_month': 'M√™s/Ano'})
        
        # Adicionar m√©dia m√≥vel de 3 meses como linha de tend√™ncia
        if len(sales_by_month_year) >= 3:
            sales_by_month_year['moving_avg'] = sales_by_month_year['gmv_success'].rolling(window=3).mean()
            fig.add_scatter(x=sales_by_month_year['purchase_year_month'], 
                           y=sales_by_month_year['moving_avg'],
                           mode='lines', 
                           name='M√©dia M√≥vel (3 meses)',
                           line=dict(color='red', width=2, dash='dash'))
        
        st.plotly_chart(fig, use_container_width=True)
        
        # An√°lise por Dia da Semana e Hora
        col1, col2 = st.columns(2)
        
        with col1:
            # Vendas por Dia da Semana
            days_order = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
            day_names_pt = ["Segunda", "Ter√ßa", "Quarta", "Quinta", "Sexta", "S√°bado", "Domingo"]
            day_map = dict(zip(days_order, day_names_pt))
            
            sales_by_dow = df.groupby('purchase_day_of_week')['gmv_success'].sum().reindex(days_order).reset_index()
            sales_by_dow['day_pt'] = sales_by_dow['purchase_day_of_week'].map(day_map)
            
            fig = px.bar(sales_by_dow,
                       x='day_pt',
                       y='gmv_success',
                       title='GMV por Dia da Semana',
                       labels={'gmv_success': 'GMV (R$)', 'day_pt': 'Dia da Semana'},
                       color='gmv_success')
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Vendas por Hora do Dia
            if 'time_purchase_hour' in df.columns:
                sales_by_hour = df.groupby('time_purchase_hour')['gmv_success'].sum().reset_index()
                
                fig = px.bar(sales_by_hour,
                           x='time_purchase_hour',
                           y='gmv_success',
                           title='GMV por Hora da Compra',
                           labels={'gmv_success': 'GMV (R$)', 'time_purchase_hour': 'Hora do Dia'},
                           color='gmv_success')
                st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.subheader("An√°lise RFM (Rec√™ncia, Frequ√™ncia, Monet√°rio)")
        
        # Calcular RFM
        rfm = calculate_rfm(df)
        
        # Distribui√ß√£o de Rec√™ncia
        st.write("### Distribui√ß√£o de Rec√™ncia (dias desde √∫ltima compra)")
        fig = px.histogram(rfm, x='recency', nbins=30,
                         title='Distribui√ß√£o de Rec√™ncia (dias desde √∫ltima compra)',
                         labels={'recency': 'Dias desde √∫ltima compra', 'count': 'Quantidade de clientes'})
        st.plotly_chart(fig, use_container_width=True)
        
        # Distribui√ß√£o de Frequ√™ncia e Valor
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("### Distribui√ß√£o de Frequ√™ncia")
            fig = px.histogram(rfm, x='frequency', nbins=20,
                             title='Distribui√ß√£o de Frequ√™ncia de Compras',
                             labels={'frequency': 'N√∫mero de compras', 'count': 'Quantidade de clientes'})
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.write("### Distribui√ß√£o de Valor Total")
            fig = px.histogram(rfm, x='monetary', nbins=20,
                             title='Distribui√ß√£o de Valor Total Gasto',
                             labels={'monetary': 'Valor Total Gasto (R$)', 'count': 'Quantidade de clientes'})
            st.plotly_chart(fig, use_container_width=True)
        
        # Correla√ß√µes RFM
        st.write("### Correla√ß√µes entre Rec√™ncia, Frequ√™ncia e Valor")
        
        fig = px.scatter(rfm, x='recency', y='frequency', size='monetary',
                       title='Rela√ß√£o entre Rec√™ncia, Frequ√™ncia e Valor',
                       labels={'recency': 'Rec√™ncia (dias)', 'frequency': 'Frequ√™ncia (compras)', 'monetary': 'Valor (R$)'},
                       opacity=0.6, color='monetary', size_max=30)
        st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        st.subheader("Segmenta√ß√£o Din√¢mica de Clientes")
        
        # Segmenta√ß√£o RFM
        rfm = calculate_rfm(df)
        rfm_segmented = categorize_rfm(rfm)
        
        # Mostrar contagem de clientes por segmento
        segment_counts = rfm_segmented['Segment'].value_counts().reset_index()
        segment_counts.columns = ['Segmento', 'Quantidade']
        
        # Calcular valor total por segmento
        segment_values = rfm_segmented.groupby('Segment')['monetary'].sum().reset_index()
        segment_values.columns = ['Segmento', 'Valor Total']
        
        # Mesclar contagens e valores
        segment_data = pd.merge(segment_counts, segment_values, on='Segmento')
        segment_data['Valor M√©dio'] = segment_data['Valor Total'] / segment_data['Quantidade']
        segment_data['Percentual de Clientes'] = segment_data['Quantidade'] / segment_data['Quantidade'].sum() * 100
        segment_data['Percentual de Valor'] = segment_data['Valor Total'] / segment_data['Valor Total'].sum() * 100
        
        # Mostrar segmentos em gr√°ficos
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("### Distribui√ß√£o de Clientes por Segmento")
            segment_data_sorted = segment_data.sort_values('Quantidade', ascending=False)
            
            fig = px.pie(segment_data_sorted, values='Quantidade', names='Segmento',
                       title='Distribui√ß√£o de Clientes por Segmento',
                       color_discrete_sequence=px.colors.qualitative.Bold)
            fig.update_traces(textposition='inside', textinfo='percent+label')
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.write("### Distribui√ß√£o de Valor por Segmento")
            segment_data_sorted = segment_data.sort_values('Valor Total', ascending=False)
            
            fig = px.pie(segment_data_sorted, values='Valor Total', names='Segmento',
                       title='Distribui√ß√£o de Valor Total por Segmento',
                       color_discrete_sequence=px.colors.qualitative.Bold)
            fig.update_traces(textposition='inside', textinfo='percent+label')
            st.plotly_chart(fig, use_container_width=True)
        
        # Tabela com dados dos segmentos
        st.write("### M√©tricas por Segmento")
        st.dataframe(segment_data[['Segmento', 'Quantidade', 'Percentual de Clientes', 'Valor Total', 'Valor M√©dio', 'Percentual de Valor']]
                    .sort_values('Valor Total', ascending=False)
                    .reset_index(drop=True)
                    .style.format({
                        'Percentual de Clientes': '{:.1f}%',
                        'Valor Total': 'R$ {:.2f}',
                        'Valor M√©dio': 'R$ {:.2f}',
                        'Percentual de Valor': '{:.1f}%'
                    }))
        
        # Exibir descri√ß√µes dos segmentos
        st.write("### Perfil dos Segmentos")
        
        # Carregar descri√ß√µes dos segmentos do arquivo personas.txt
        try:
            with open('personas.txt', 'r', encoding='utf-8') as file:
                personas = [line.strip() for line in file.readlines() if line.strip()]
                
                # Criar dicion√°rio de personas
                personas_dict = {}
                for persona in personas:
                    if ':' in persona:
                        key, desc = persona.split(':', 1)
                        personas_dict[key.strip()] = desc.strip()
                
                # Exibir em formato de cart√µes
                for i in range(0, len(personas), 2):
                    col1, col2 = st.columns(2)
                    
                    # Coluna 1
                    if i < len(personas):
                        persona = personas[i]
                        if ':' in persona:
                            segment, description = persona.split(':', 1)
                        else:
                            segment, description = persona, ""
                        
                        with col1:
                            st.markdown(f"""
                            <div style="background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 10px;">
                                <h4 style="color: #1E3A8A;">{segment.strip()}</h4>
                                <p>{description.strip()}</p>
                            </div>
                            """, unsafe_allow_html=True)
                    
                    # Coluna 2
                    if i + 1 < len(personas):
                        persona = personas[i + 1]
                        if ':' in persona:
                            segment, description = persona.split(':', 1)
                        else:
                            segment, description = persona, ""
                        
                        with col2:
                            st.markdown(f"""
                            <div style="background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 10px;">
                                <h4 style="color: #1E3A8A;">{segment.strip()}</h4>
                                <p>{description.strip()}</p>
                            </div>
                            """, unsafe_allow_html=True)
        except Exception as e:
            st.error(f"Erro ao carregar descri√ß√µes dos segmentos: {str(e)}")
    
    with tab4:
        st.subheader("Evolu√ß√£o dos Segmentos ao Longo do Tempo")
        
        # An√°lise de cohort para entender evolu√ß√£o do comportamento
        try:
            retention_matrix = create_cohort_analysis(df)
            
            # Mostrar matriz de reten√ß√£o
            st.write("### Matriz de Reten√ß√£o de Clientes")
            st.write("Percentual de clientes que continuam comprando ap√≥s sua primeira compra")
            
            # Formatar matriz para exibi√ß√£o
            retention_styled = retention_matrix.style.background_gradient(cmap='Blues')
            retention_styled = retention_styled.format("{:.1f}%")
            
            st.dataframe(retention_styled)
            
            # Visualiza√ß√£o da matriz como heatmap
            st.write("### Heatmap de Reten√ß√£o")
            
            # Criar dataframe adequado para o plotly
            cohort_pivot = retention_matrix.reset_index()
            cohort_pivot.columns = cohort_pivot.columns.astype(str)
            cohort_pivot['primeira_compra'] = cohort_pivot['primeira_compra'].astype(str)
            
            cohort_long = cohort_pivot.melt(
                id_vars=['primeira_compra'],
                var_name='Period',
                value_name='Retention'
            )
            cohort_long['Period'] = cohort_long['Period'].astype(int)
            
            # Plotar heatmap
            fig = px.imshow(
                retention_matrix.values,
                labels=dict(x="Per√≠odo (meses)", y="M√™s da Primeira Compra", color="Reten√ß√£o (%)"),
                x=[str(i) for i in retention_matrix.columns],
                y=[str(cohort) for cohort in retention_matrix.index],
                color_continuous_scale='Blues',
                zmin=0,
                zmax=100
            )
            fig.update_layout(
                xaxis_title="Meses desde a primeira compra",
                yaxis_title="Cohort (m√™s da primeira compra)",
                coloraxis_colorbar=dict(title="Reten√ß√£o (%)")
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # Curva de reten√ß√£o m√©dia
            st.write("### Curva de Reten√ß√£o M√©dia")
            avg_retention = retention_matrix.mean(axis=0)
            
            fig = px.line(
                x=avg_retention.index.astype(str),
                y=avg_retention.values,
                markers=True,
                labels={'x': 'Per√≠odo (meses)', 'y': 'Taxa de Reten√ß√£o M√©dia (%)'},
                title='Taxa de Reten√ß√£o M√©dia ao Longo do Tempo'
            )
            
            # Adicionar anota√ß√µes aos pontos
            for i, val in enumerate(avg_retention.values):
                fig.add_annotation(
                    x=i,
                    y=val,
                    text=f"{val:.1f}%",
                    showarrow=False,
                    yshift=10
                )
            
            st.plotly_chart(fig, use_container_width=True)
            
        except Exception as e:
            st.error(f"Erro ao calcular matriz de reten√ß√£o: {str(e)}")
            st.info("Esta an√°lise requer dados hist√≥ricos suficientes para criar cohorts mensais.")
        
        # Dicas de a√ß√£o baseadas na an√°lise de cohort
        st.write("### Insights e Recomenda√ß√µes")
        
        st.markdown("""
        <div style="background-color: #e8f4f8; padding: 15px; border-radius: 5px; margin-bottom: 15px;">
            <h4>Oportunidades Identificadas:</h4>
            <ul>
                <li><strong>Potencial de Reativa√ß√£o</strong>: Clientes que pararam de comprar ap√≥s o per√≠odo 3 representam uma oportunidade de reativa√ß√£o.</li>
                <li><strong>Programas de Fidelidade</strong>: Implementar programas focados em clientes que mant√™m alta reten√ß√£o nos primeiros 3 meses.</li>
                <li><strong>Personaliza√ß√£o do Ciclo de Vida</strong>: Adaptar comunica√ß√µes baseadas no est√°gio do cliente e comportamento hist√≥rico de sua cohort.</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

def parte2_analise(df):
    """An√°lise da Parte 2: Proje√ß√£o de Ciclo de Compra e Timing Ideal."""
    st.header("‚è±Ô∏è Proje√ß√£o de Ciclo de Compra e Timing Ideal")
    
    st.markdown("""
    <div style="background-color: #e8f4f8; padding: 15px; border-radius: 5px; margin-bottom: 15px;">
        <p>Com base no perfil comportamental estabelecido, o InfiniteBus estima a janela de tempo mais prov√°vel 
        para a pr√≥xima compra do cliente. Isso considera a frequ√™ncia individual, rec√™ncia, intervalo m√©dio entre 
        compras e a sazonalidade das compras anteriores, tanto do indiv√≠duo quanto de seu segmento.</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Criar abas para diferentes an√°lises de timing
    subtab1, subtab2, subtab3, subtab4 = st.tabs([
        "üìä An√°lise de Intervalo", 
        "üîÆ Previs√£o de Recompra", 
        "üìÖ Sazonalidade",
        "üì± Simulador de Timing"
    ])
    
    with subtab1:
        st.subheader("An√°lise de Intervalos entre Compras")
        
        # Ordenar dados por cliente e data
        df_sorted = df.sort_values(['fk_contact', 'date_purchase'])
        
        # Calcular o intervalo entre compras consecutivas para o mesmo cliente
        df_sorted['prev_purchase'] = df_sorted.groupby('fk_contact')['date_purchase'].shift(1)
        df_sorted['days_since_prev_purchase'] = (df_sorted['date_purchase'] - df_sorted['prev_purchase']).dt.days
        
        # Remover valores inv√°lidos ou nulos
        df_intervals = df_sorted.dropna(subset=['days_since_prev_purchase'])
        df_intervals = df_intervals[df_intervals['days_since_prev_purchase'] > 0]
        
        # Mostrar estat√≠sticas de intervalo
        st.write("### Estat√≠sticas do Intervalo entre Compras (dias)")
        
        interval_stats = {
            "M√©dia": df_intervals['days_since_prev_purchase'].mean(),
            "Mediana": df_intervals['days_since_prev_purchase'].median(),
            "M√≠nimo": df_intervals['days_since_prev_purchase'].min(),
            "M√°ximo": df_intervals['days_since_prev_purchase'].max(),
            "Desvio Padr√£o": df_intervals['days_since_prev_purchase'].std()
        }
        
        col1, col2, col3, col4, col5 = st.columns(5)
        with col1:
            st.metric("M√©dia", f"{interval_stats['M√©dia']:.1f} dias")
        with col2:
            st.metric("Mediana", f"{interval_stats['Mediana']:.1f} dias")
        with col3:
            st.metric("M√≠nimo", f"{interval_stats['M√≠nimo']:.1f} dias")
        with col4:
            st.metric("M√°ximo", f"{interval_stats['M√°ximo']:.1f} dias")
        with col5:
            st.metric("Desvio Padr√£o", f"{interval_stats['Desvio Padr√£o']:.1f} dias")
        
        # Distribui√ß√£o de intervalos
        st.write("### Distribui√ß√£o de Intervalos entre Compras")
        
        # Limitar intervalo para visualiza√ß√£o (removendo outliers extremos)
        interval_limit = np.percentile(df_intervals['days_since_prev_purchase'], 99)
        df_intervals_viz = df_intervals[df_intervals['days_since_prev_purchase'] <= interval_limit]
        
        fig = px.histogram(
            df_intervals_viz, 
            x='days_since_prev_purchase',
            nbins=50,
            title='Distribui√ß√£o de Intervalos entre Compras',
            labels={'days_since_prev_purchase': 'Intervalo (dias)', 'count': 'N√∫mero de Ocorr√™ncias'}
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Intervalo m√©dio por segmento de cliente
        st.write("### Intervalo M√©dio por Segmento de Cliente")
        
        # Calcular RFM para segmenta√ß√£o
        rfm = calculate_rfm(df)
        rfm_segmented = categorize_rfm(rfm)
        
        # Mesclar com o dataframe de intervalos
        df_intervals_segment = pd.merge(
            df_intervals,
            rfm_segmented[['Segment']],
            left_on='fk_contact',
            right_index=True,
            how='inner'
        )
        
        # Calcular intervalo m√©dio por segmento
        segment_intervals = df_intervals_segment.groupby('Segment')['days_since_prev_purchase'].agg(['mean', 'median', 'count']).reset_index()
        segment_intervals.columns = ['Segmento', 'M√©dia (dias)', 'Mediana (dias)', 'Quantidade']
        segment_intervals = segment_intervals.sort_values('M√©dia (dias)')
        
        # Visualizar intervalo m√©dio por segmento
        fig = px.bar(
            segment_intervals,
            x='Segmento',
            y='M√©dia (dias)',
            color='Segmento',
            title='Intervalo M√©dio entre Compras por Segmento',
            text='M√©dia (dias)',
            hover_data=['Mediana (dias)', 'Quantidade']
        )
        fig.update_traces(texttemplate='%{text:.1f}', textposition='outside')
        st.plotly_chart(fig, use_container_width=True)
    
    with subtab2:
        st.subheader("Previs√£o de Probabilidade de Recompra")
        
        # Primeiro, calcular RFM
        rfm = calculate_rfm(df)
        
        # Filtrar o DataFrame original para incluir apenas clientes que est√£o no RFM
        clientes_validos = rfm.index.tolist()
        df_filtered = df[df['fk_contact'].isin(clientes_validos)]
        
        # Ordenar o DataFrame por cliente e data para c√°lculos corretos de next_purchase
        df_filtered = df_filtered.sort_values(['fk_contact', 'date_purchase'])
        
        # Feature engineering para a previs√£o de recompra
        # Calcular dias at√© a pr√≥xima compra para cada cliente
        df_filtered['next_purchase'] = df_filtered.groupby('fk_contact')['date_purchase'].shift(-1)
        df_filtered['days_until_next_purchase'] = (df_filtered['next_purchase'] - df_filtered['date_purchase']).dt.days
        
        # Definir janelas de tempo para previs√£o
        df_filtered['will_buy_next_7_days'] = (df_filtered['days_until_next_purchase'] <= 7).astype(int)
        df_filtered['will_buy_next_15_days'] = (df_filtered['days_until_next_purchase'] <= 15).astype(int)
        df_filtered['will_buy_next_30_days'] = (df_filtered['days_until_next_purchase'] <= 30).astype(int)
        
        # Remover linhas com valores nulos
        df_clean = df_filtered.dropna(subset=['days_until_next_purchase'])
        
        # Agregar dados por cliente para ter uma linha por cliente no final
        cliente_ultima_compra = df_clean.groupby('fk_contact')['date_purchase'].max().reset_index()
        cliente_ultima_compra.columns = ['fk_contact', 'ultima_compra']
        
        # Mesclar com o conjunto limpo para obter apenas a √∫ltima compra de cada cliente
        df_ultima_compra = pd.merge(
            df_clean, 
            cliente_ultima_compra,
            on='fk_contact',
            how='inner'
        )
        df_ultima_compra = df_ultima_compra[df_ultima_compra['date_purchase'] == df_ultima_compra['ultima_compra']]
        
        try:
            # Agora temos um DataFrame com uma linha por cliente
            X = rfm.loc[df_ultima_compra['fk_contact']][['recency', 'frequency', 'monetary']]
            
            # Escolher qual janela de tempo visualizar
            time_window = st.selectbox(
                "Selecione a janela de tempo para previs√£o:",
                ['7 dias', '15 dias', '30 dias'],
                index=1
            )
            
            if time_window == '7 dias':
                y = df_ultima_compra['will_buy_next_7_days']
                target_col = 'will_buy_next_7_days'
            elif time_window == '15 dias':
                y = df_ultima_compra['will_buy_next_15_days']
                target_col = 'will_buy_next_15_days'
            else:
                y = df_ultima_compra['will_buy_next_30_days']
                target_col = 'will_buy_next_30_days'
            
            # Verificar se X e y t√™m o mesmo tamanho
            if len(X) != len(y):
                st.error(f"Erro: X ({len(X)} amostras) e y ({len(y)} amostras) t√™m tamanhos diferentes.")
            else:
                # Treinar modelo otimizado para mem√≥ria
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
                
                model = RandomForestClassifier(
                    n_estimators=50,
                    max_depth=5,
                    min_samples_split=10,
                    min_samples_leaf=5,
                    random_state=42,
                    n_jobs=-1
                )
                
                with st.spinner(f'Treinando modelo de previs√£o para {time_window}...'):
                    model.fit(X_train, y_train)
                
                # Avaliar modelo
                y_pred = model.predict(X_test)
                auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])
                f1 = f1_score(y_test, y_pred)
                
                # Mostrar m√©tricas
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("AUC", f"{auc:.2f}")
                with col2:
                    st.metric("F1 Score", f"{f1:.2f}")
                
                # Exibir import√¢ncia das features
                st.write("### Import√¢ncia das Features")
                feature_importance = pd.DataFrame({
                    'Feature': ['Rec√™ncia (dias)', 'Frequ√™ncia (compras)', 'Valor Total (R$)'],
                    'Importance': model.feature_importances_
                }).sort_values('Importance', ascending=False)
                
                fig = px.bar(
                    feature_importance, 
                    x='Feature', 
                    y='Importance', 
                    title=f'Import√¢ncia das Features para Previs√£o de Recompra em {time_window}'
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # Taxa de convers√£o por segmento
                st.write(f"### Taxa de Convers√£o por Segmento (Recompra em {time_window})")
                
                # Mesclar previs√µes com segmentos
                df_pred = pd.DataFrame({
                    'fk_contact': df_ultima_compra['fk_contact'].values,
                    'actual': y.values,
                    'pred_prob': model.predict_proba(X)[:, 1]
                })
                
                df_pred = pd.merge(
                    df_pred,
                    rfm_segmented[['Segment']],
                    left_on='fk_contact',
                    right_index=True,
                    how='inner'
                )
                
                # Calcular taxa de convers√£o real por segmento
                segment_conversion = df_pred.groupby('Segment')['actual'].agg(['mean', 'count']).reset_index()
                segment_conversion.columns = ['Segmento', 'Taxa de Convers√£o', 'Quantidade']
                segment_conversion['Taxa de Convers√£o'] = segment_conversion['Taxa de Convers√£o'] * 100
                segment_conversion = segment_conversion.sort_values('Taxa de Convers√£o', ascending=False)
                
                # Visualizar taxa de convers√£o por segmento
                fig = px.bar(
                    segment_conversion,
                    x='Segmento',
                    y='Taxa de Convers√£o',
                    color='Segmento',
                    title=f'Taxa de Convers√£o por Segmento (Recompra em {time_window})',
                    text='Taxa de Convers√£o',
                    hover_data=['Quantidade']
                )
                fig.update_traces(texttemplate='%{text:.1f}%', textposition='outside')
                st.plotly_chart(fig, use_container_width=True)
                
                # Lista de clientes com maior probabilidade de compra
                st.write("### Top Clientes com Maior Probabilidade de Recompra")
                
                df_pred = df_pred.sort_values('pred_prob', ascending=False)
                top_clients = df_pred.head(10)
                
                # Mesclar com dados RFM
                top_clients_rfm = pd.merge(
                    top_clients,
                    rfm,
                    left_on='fk_contact',
                    right_index=True,
                    how='inner'
                )
                
                # Mostrar tabela de clientes potenciais
                st.dataframe(
                    top_clients_rfm[['fk_contact', 'Segment', 'pred_prob', 'recency', 'frequency', 'monetary']]
                    .rename(columns={
                        'fk_contact': 'ID do Cliente',
                        'Segment': 'Segmento',
                        'pred_prob': 'Probabilidade (%)',
                        'recency': 'Rec√™ncia (dias)',
                        'frequency': 'Frequ√™ncia',
                        'monetary': 'Valor Total (R$)'
                    })
                    .style.format({
                        'Probabilidade (%)': '{:.1%}',
                        'Valor Total (R$)': 'R$ {:.2f}'
                    })
                )
        
        except Exception as e:
            st.error(f"Erro ao processar a previs√£o de recompra: {str(e)}")
            import traceback
            st.code(traceback.format_exc())
    
    with subtab3:
        st.subheader("An√°lise de Sazonalidade e Padr√µes Temporais")
        
        # An√°lise por m√™s
        st.write("### Sazonalidade Mensal")
        
        # Vendas por m√™s
        monthly_sales = df.groupby('purchase_month')['gmv_success'].sum().reset_index()
        
        # Ordenar meses corretamente
        month_order = ['January', 'February', 'March', 'April', 'May', 'June', 
                       'July', 'August', 'September', 'October', 'November', 'December']
        month_order_pt = ['Janeiro', 'Fevereiro', 'Mar√ßo', 'Abril', 'Maio', 'Junho', 
                         'Julho', 'Agosto', 'Setembro', 'Outubro', 'Novembro', 'Dezembro']
        month_map = dict(zip(month_order, month_order_pt))
        
        # Mapear nomes dos meses para portugu√™s e ordenar
        monthly_sales['month_pt'] = monthly_sales['purchase_month'].map(month_map)
        monthly_sales['month_order'] = monthly_sales['purchase_month'].apply(lambda x: month_order.index(x) if x in month_order else -1)
        monthly_sales = monthly_sales.sort_values('month_order')
        
        # Plotar vendas por m√™s
        fig = px.bar(
            monthly_sales,
            x='month_pt',
            y='gmv_success',
            title='GMV por M√™s',
            labels={'gmv_success': 'GMV (R$)', 'month_pt': 'M√™s'},
            color='gmv_success'
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # An√°lise por dia da semana e hora
        col1, col2 = st.columns(2)
        
        with col1:
            # Frequ√™ncia de compras por dia da semana
            days_order = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
            day_names_pt = ["Segunda", "Ter√ßa", "Quarta", "Quinta", "Sexta", "S√°bado", "Domingo"]
            day_map = dict(zip(days_order, day_names_pt))
            
            purchases_by_dow = df.groupby('purchase_day_of_week').size().reindex(days_order).reset_index()
            purchases_by_dow.columns = ['purchase_day_of_week', 'count']
            purchases_by_dow['day_pt'] = purchases_by_dow['purchase_day_of_week'].map(day_map)
            
            fig = px.bar(
                purchases_by_dow,
                x='day_pt',
                y='count',
                title='Frequ√™ncia de Compras por Dia da Semana',
                labels={'count': 'Quantidade', 'day_pt': 'Dia da Semana'},
                color='count'
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Frequ√™ncia de compras por hora do dia
            if 'time_purchase_hour' in df.columns:
                purchases_by_hour = df.groupby('time_purchase_hour').size().reset_index()
                purchases_by_hour.columns = ['time_purchase_hour', 'count']
                
                fig = px.bar(
                    purchases_by_hour,
                    x='time_purchase_hour',
                    y='count',
                    title='Frequ√™ncia de Compras por Hora do Dia',
                    labels={'count': 'Quantidade', 'time_purchase_hour': 'Hora do Dia'},
                    color='count'
                )
                st.plotly_chart(fig, use_container_width=True)
        
        # Heatmap de dia da semana vs hora
        st.write("### Padr√£o de Compras: Dia da Semana vs Hora")
        
        if 'time_purchase_hour' in df.columns:
            # Criar heatmap de dia vs hora
            dow_hour = df.groupby(['purchase_day_of_week', 'time_purchase_hour']).size().reset_index()
            dow_hour.columns = ['day', 'hour', 'count']
            
            # Converter para formato adequado para heatmap
            dow_hour_pivot = dow_hour.pivot(index='day', columns='hour', values='count')
            
            # Reordenar dias da semana
            dow_hour_pivot = dow_hour_pivot.reindex(days_order)
            
            # Criar heatmap
            fig = px.imshow(
                dow_hour_pivot.values,
                labels=dict(x="Hora do Dia", y="Dia da Semana", color="Quantidade"),
                x=dow_hour_pivot.columns,
                y=[day_map[day] for day in dow_hour_pivot.index],
                color_continuous_scale='Viridis'
            )
            
            fig.update_layout(
                xaxis_title="Hora do Dia",
                yaxis_title="Dia da Semana",
                coloraxis_colorbar=dict(title="Quantidade")
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    with subtab4:
        st.subheader("Simulador de Timing Ideal para Contato")
        
        st.markdown("""
        <div style="background-color: #f1f9ff; padding: 15px; border-radius: 5px; margin-bottom: 15px;">
            <p>Este simulador permite estimar o melhor momento para contatar um cliente com base em seu perfil comportamental.
            Ajuste os par√¢metros para ver a probabilidade de recompra em diferentes janelas de tempo.</p>
        </div>
        """, unsafe_allow_html=True)
        
        try:
            # Primeiro, treinar modelos para diferentes janelas de tempo
            # Usar o mesmo c√≥digo da subtab2 para preparar os dados
            rfm = calculate_rfm(df)
            clientes_validos = rfm.index.tolist()
            df_filtered = df[df['fk_contact'].isin(clientes_validos)]
            df_filtered = df_filtered.sort_values(['fk_contact', 'date_purchase'])
            
            df_filtered['next_purchase'] = df_filtered.groupby('fk_contact')['date_purchase'].shift(-1)
            df_filtered['days_until_next_purchase'] = (df_filtered['next_purchase'] - df_filtered['date_purchase']).dt.days
            
            df_filtered['will_buy_next_7_days'] = (df_filtered['days_until_next_purchase'] <= 7).astype(int)
            df_filtered['will_buy_next_15_days'] = (df_filtered['days_until_next_purchase'] <= 15).astype(int)
            df_filtered['will_buy_next_30_days'] = (df_filtered['days_until_next_purchase'] <= 30).astype(int)
            
            df_clean = df_filtered.dropna(subset=['days_until_next_purchase'])
            
            cliente_ultima_compra = df_clean.groupby('fk_contact')['date_purchase'].max().reset_index()
            cliente_ultima_compra.columns = ['fk_contact', 'ultima_compra']
            
            df_ultima_compra = pd.merge(df_clean, cliente_ultima_compra, on='fk_contact', how='inner')
            df_ultima_compra = df_ultima_compra[df_ultima_compra['date_purchase'] == df_ultima_compra['ultima_compra']]
            
            X = rfm.loc[df_ultima_compra['fk_contact']][['recency', 'frequency', 'monetary']]
            
            # Verificar se h√° dados suficientes
            if len(X) < 100:
                st.warning("Poucos dados dispon√≠veis para o simulador. Os resultados podem n√£o ser precisos.")
            
            # Criar modelos para cada janela de tempo
            models = {}
            for window, days in [('7_dias', 7), ('15_dias', 15), ('30_dias', 30)]:
                target = f'will_buy_next_{days}_days'
                y = df_ultima_compra[target]
                
                if len(X) == len(y):
                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
                    
                    model = RandomForestClassifier(
                        n_estimators=50,
                        max_depth=5,
                        min_samples_split=10,
                        min_samples_leaf=5,
                        random_state=42,
                        n_jobs=-1
                    )
                    
                    model.fit(X_train, y_train)
                    models[window] = model
            
            with st.container():
                st.write("### Configure o Perfil do Cliente")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    recency = st.slider("Timing: Dias desde √∫ltima compra", 1, 365, 35, key="timing_recency_slider")
                with col2:
                    frequency = st.slider("Timing: N√∫mero de compras", 1, 20, 4, key="timing_frequency_slider")
                with col3:
                    monetary = st.slider("Timing: Valor total gasto (R$)", 100, 5000, 1500, key="timing_monetary_slider")
                
                # Fazer previs√µes com os modelos
                client_profile = np.array([[recency, frequency, monetary]])
                
                # Mostrar resultados em uma barra de progresso estilizada
                st.write("### Probabilidade de Recompra")
                
                results = {}
                for window, model in models.items():
                    prob = model.predict_proba(client_profile)[0][1]
                    days = window.split('_')[0]
                    results[f'Pr√≥ximos {days} dias'] = prob
                
                # Exibir probabilidades como barras de progresso
                for window, prob in results.items():
                    progress_color = "green" if prob > 0.6 else "orange" if prob > 0.3 else "red"
                    progress_html = f"""
                    <div style="margin-bottom: 15px;">
                        <div style="display: flex; justify-content: space-between; margin-bottom: 5px;">
                            <span style="font-weight: 500;">{window}</span>
                            <span style="font-weight: 600;">{prob:.1%}</span>
                        </div>
                        <div style="background-color: #e0e0e0; border-radius: 10px; height: 10px;">
                            <div style="width: {prob*100}%; background-color: {progress_color}; height: 10px; border-radius: 10px;"></div>
                        </div>
                    </div>
                    """
                    st.markdown(progress_html, unsafe_allow_html=True)
                
                # Recomenda√ß√£o de timing
                st.write("### Recomenda√ß√£o de Timing")
                
                # Determinar melhor janela de tempo para contato
                if results:
                    best_window = max(results.items(), key=lambda x: x[1])
                    
                    # Calcular dia da semana e hora recomendados com base nos dados
                    if 'time_purchase_hour' in df.columns:
                        # Encontrar o dia e hora com maior frequ√™ncia de compras
                        dow_hour = df.groupby(['purchase_day_of_week', 'time_purchase_hour']).size().reset_index()
                        dow_hour.columns = ['day', 'hour', 'count']
                        best_time = dow_hour.sort_values('count', ascending=False).iloc[0]
                        
                        best_day_name = day_map.get(best_time['day'], best_time['day'])
                        best_hour = best_time['hour']
                        
                        # Criar recomenda√ß√£o de contato
                        recommendation_html = f"""
                        <div style="background-color: #e8f5e9; padding: 15px; border-radius: 5px; margin-top: 15px;">
                            <h4 style="color: #2e7d32; margin-top: 0;">Recomenda√ß√£o de Contato</h4>
                            <p>Com base no perfil do cliente e nos padr√µes hist√≥ricos, recomendamos:</p>
                            <ul>
                                <li><strong>Quando contatar:</strong> Nos {best_window[0].lower()} ({best_window[1]:.1%} de probabilidade)</li>
                                <li><strong>Melhor dia:</strong> {best_day_name}</li>
                                <li><strong>Melhor hor√°rio:</strong> Por volta das {best_hour}h</li>
                            </ul>
                            <p style="margin-bottom: 0;"><strong>Estrat√©gia sugerida:</strong> 
                                {
                                    "Oferta agressiva com prazo limitado" if best_window[1] > 0.7 else
                                    "Lembrete personalizado com benef√≠cios" if best_window[1] > 0.4 else
                                    "Comunica√ß√£o informativa e sem press√£o"
                                }
                            </p>
                        </div>
                        """
                        st.markdown(recommendation_html, unsafe_allow_html=True)
                    
        except Exception as e:
            st.error(f"Erro ao processar o simulador de timing: {str(e)}")
            import traceback
            st.code(traceback.format_exc())

def parte3_analise(df):
    """An√°lise da Parte 3: A Estrada √† Frente."""
    st.header("A Estrada √† Frente")
    st.write("An√°lise de classifica√ß√£o multi-classe para recomenda√ß√£o de rotas.")
    
    try:
        # Mostrar as rotas mais populares
        st.subheader("Rotas Mais Populares")
        
        # Feature engineering para criar a coluna de rota
        df['route'] = df['place_origin_departure'] + " -> " + df['place_destination_departure']
        
        # Exibir as rotas mais populares
        route_counts = df['route'].value_counts().reset_index()
        route_counts.columns = ['Rota', 'Frequ√™ncia']
        top_routes = route_counts.head(10)
        
        fig = px.bar(top_routes, x='Rota', y='Frequ√™ncia', title='10 Rotas Mais Populares')
        st.plotly_chart(fig, use_container_width=True)
        
        # Usar apenas as N rotas mais populares para evitar problemas de mem√≥ria
        TOP_N_ROUTES = 10  # Limitar a 10 rotas mais populares
        top_route_names = top_routes['Rota'].tolist()
        
        # Filtrar o DataFrame para incluir apenas as rotas mais populares
        df_top_routes = df[df['route'].isin(top_route_names)].copy()
        
        if len(df_top_routes) == 0:
            st.error("Sem dados suficientes para an√°lise ap√≥s filtragem das rotas")
            return
            
        # Informa√ß√£o sobre a redu√ß√£o do conjunto de dados
        st.info(f"An√°lise limitada √†s {TOP_N_ROUTES} rotas mais populares ({len(df_top_routes)} de {len(df)} registros).")
        
        # Calcular m√©tricas RFM
        # Agrupar por cliente para obter recency, frequency e monetary
        rfm = df_top_routes.groupby('fk_contact').agg({
            'date_purchase': lambda x: (pd.Timestamp.now() - x.max()).days,  # Rec√™ncia
            'nk_ota_localizer_id': 'count',  # Frequ√™ncia
            'gmv_success': 'sum'  # Monet√°rio
        }).rename(columns={
            'date_purchase': 'recency',
            'nk_ota_localizer_id': 'frequency',
            'gmv_success': 'monetary'
        })
        
        # Codificar rotas - limitadas √†s TOP_N mais populares
        le = LabelEncoder()
        df_top_routes['route_encoded'] = le.fit_transform(df_top_routes['route'])
        route_mapping = dict(zip(le.classes_, range(len(le.classes_))))
        
        # Ordenar o DataFrame por cliente e data para pegar a √∫ltima rota de cada cliente
        df_top_routes = df_top_routes.sort_values(['fk_contact', 'date_purchase'])
        
        # Pegar a √∫ltima rota de cada cliente
        last_routes = df_top_routes.groupby('fk_contact').last()[['route', 'route_encoded']]
        
        # Mesclar RFM com as √∫ltimas rotas
        modelo_df = rfm.join(last_routes, how='inner')
        
        # Verificar se temos dados suficientes
        if len(modelo_df) < 50:
            st.warning("Poucos dados dispon√≠veis para o modelo. Os resultados podem n√£o ser confi√°veis.")
        
        # Prepare X e y para o modelo
        X = modelo_df[['recency', 'frequency', 'monetary']]
        y = modelo_df['route_encoded']
        
        # Amostragem para grandes conjuntos de dados (se necess√°rio)
        MAX_SAMPLES = 5000
        if len(X) > MAX_SAMPLES:
            st.info(f"Amostrando {MAX_SAMPLES} registros dos {len(X)} dispon√≠veis para otimizar o uso de mem√≥ria.")
            indices = np.random.choice(len(X), MAX_SAMPLES, replace=False)
            X = X.iloc[indices]
            y = y.iloc[indices]
        
        # Treinar modelo com par√¢metros otimizados para mem√≥ria
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # Par√¢metros otimizados para usar menos mem√≥ria
        model = RandomForestClassifier(
            n_estimators=50,           # Menos √°rvores
            max_depth=10,              # Profundidade limitada
            min_samples_split=10,      # Requer mais amostras para dividir
            min_samples_leaf=5,        # Requer mais amostras por folha
            max_features='sqrt',       # Usa apenas sqrt(n_features) features
            random_state=42,
            n_jobs=-1                  # Usar todos os n√∫cleos da CPU
        )
        
        with st.spinner('Treinando modelo de recomenda√ß√£o de rotas...'):
            model.fit(X_train, y_train)
        
        # Avaliar modelo
        y_pred = model.predict(X_test)
        accuracy = (y_pred == y_test).mean()
        
        # M√©tricas de desempenho
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Acur√°cia do Modelo", f"{accuracy:.2f}")
        with col2:
            n_classes = len(np.unique(y))
            baseline = 1.0 / n_classes if n_classes > 0 else 0
            st.metric("Melhoria sobre Baseline", f"{accuracy/baseline:.1f}x", 
                     delta=f"{(accuracy-baseline)*100:.1f}%")
        
        # Exibir import√¢ncia das features
        st.subheader("Import√¢ncia das Features")
        feature_importance = pd.DataFrame({
            'Feature': ['Rec√™ncia (dias)', 'Frequ√™ncia (compras)', 'Valor Total (R$)'],
            'Importance': model.feature_importances_
        }).sort_values('Importance', ascending=False)
        
        fig = px.bar(feature_importance, x='Feature', y='Importance', 
                    title='Import√¢ncia das Features na Recomenda√ß√£o de Rotas')
        st.plotly_chart(fig, use_container_width=True)
        
        # Demonstra√ß√£o de previs√£o para diferentes perfis de cliente
        st.subheader("Simulador de Recomenda√ß√£o")
        st.write("Ajuste os valores para simular recomenda√ß√µes para diferentes perfis de cliente:")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            recency = st.slider("Rota: Dias desde √∫ltima compra", 1, 365, 35, key="route_recency_slider")
        with col2:
            frequency = st.slider("Rota: N√∫mero de compras", 1, 20, 4, key="route_frequency_slider")
        with col3:
            monetary = st.slider("Rota: Valor total gasto (R$)", 100, 5000, 1500, key="route_monetary_slider")
        
        # Fazer previs√£o com os valores do slider
        cliente_perfil = np.array([[recency, frequency, monetary]])
        rota_prevista_id = model.predict(cliente_perfil)[0]
        
        # Obter o nome da rota a partir do ID
        rota_prevista_nome = le.inverse_transform([rota_prevista_id])[0]
        
        # Mostrar rota recomendada
        st.success(f"**Rota Recomendada:** {rota_prevista_nome}")
        
        # Mostrar probabilidades para todas as rotas
        probs = model.predict_proba(cliente_perfil)[0]
        # Combinar as rotas com suas probabilidades e ordenar
        routes_probs = [(route, prob) for route, prob in zip(le.classes_, probs)]
        routes_probs.sort(key=lambda x: x[1], reverse=True)
        
        # Mostrar top 3 rotas mais prov√°veis
        st.write("**Top 3 rotas mais prov√°veis:**")
        for route, prob in routes_probs[:3]:
            st.write(f"- {route}: {prob*100:.1f}%")
        
    except MemoryError:
        st.error("Erro de mem√≥ria ao processar os dados. Tente reduzir o conjunto de dados ou otimizar os par√¢metros.")
    except Exception as e:
        st.error(f"Erro ao processar an√°lise: {str(e)}")
        st.info("Dica: Verifique se todas as colunas necess√°rias est√£o presentes no DataFrame.")
        import traceback
        st.code(traceback.format_exc())

def categorize_rfm(rfm):
    """
    Categoriza os clientes em segmentos com base nas pontua√ß√µes RFM.
    Usa quartis para criar uma classifica√ß√£o de 1-4 para cada dimens√£o.
    """
    # Criar quartis para rec√™ncia (menor √© melhor)
    rfm['R_quartile'] = pd.qcut(rfm['recency'], 4, labels=range(4, 0, -1))
    
    # Criar quartis para frequ√™ncia (maior √© melhor)
    rfm['F_quartile'] = pd.qcut(rfm['frequency'].rank(method='first'), 4, labels=range(1, 5))
    
    # Criar quartis para valor monet√°rio (maior √© melhor)
    rfm['M_quartile'] = pd.qcut(rfm['monetary'].rank(method='first'), 4, labels=range(1, 5))
    
    # Converter para inteiros para c√°lculos
    rfm['R_quartile'] = rfm['R_quartile'].astype(int)
    rfm['F_quartile'] = rfm['F_quartile'].astype(int)
    rfm['M_quartile'] = rfm['M_quartile'].astype(int)
    
    # Calcular a pontua√ß√£o RFM (combina√ß√£o das tr√™s dimens√µes)
    rfm['RFM_score'] = rfm['R_quartile'] + rfm['F_quartile'] + rfm['M_quartile']
    
    # Segmentar clientes
    rfm['Segment'] = 'Outros'
    
    # Campe√µes: Clientes que compraram recentemente, compram frequentemente e gastam muito
    rfm.loc[rfm['RFM_score'] >= 10, 'Segment'] = 'Campe√µes'
    
    # Leais: Compram regularmente, mas n√£o s√£o os mais recentes
    rfm.loc[(rfm['RFM_score'] >= 8) & (rfm['RFM_score'] < 10), 'Segment'] = 'Leais'
    
    # Potenciais: Compraram recentemente, mas n√£o com tanta frequ√™ncia
    rfm.loc[(rfm['R_quartile'] >= 3) & (rfm['F_quartile'] < 3) & (rfm['M_quartile'] >= 3), 'Segment'] = 'Potenciais'
    
    # Em Risco: Bons clientes que n√£o compram h√° algum tempo
    rfm.loc[(rfm['R_quartile'] <= 2) & (rfm['F_quartile'] >= 3) & (rfm['M_quartile'] >= 3), 'Segment'] = 'Em Risco'
    
    # Hibernando: Compraram com alguma frequ√™ncia, mas h√° muito tempo
    rfm.loc[(rfm['R_quartile'] <= 2) & (rfm['F_quartile'] <= 2) & (rfm['M_quartile'] >= 2), 'Segment'] = 'Hibernando'
    
    # Precisam Aten√ß√£o: Recentes, mas n√£o gastam muito
    rfm.loc[(rfm['R_quartile'] >= 3) & (rfm['F_quartile'] <= 2) & (rfm['M_quartile'] <= 2), 'Segment'] = 'Precisam Aten√ß√£o'
    
    # Novos: Compraram muito recentemente pela primeira vez
    rfm.loc[(rfm['R_quartile'] == 4) & (rfm['F_quartile'] == 1), 'Segment'] = 'Novos'
    
    # Perdidos: N√£o compram h√° muito tempo e compraram poucas vezes
    rfm.loc[(rfm['R_quartile'] <= 2) & (rfm['F_quartile'] <= 1) & (rfm['M_quartile'] <= 1), 'Segment'] = 'Perdidos'
    
    return rfm

def create_cohort_analysis(df):
    """
    Cria uma an√°lise de cohort com base na primeira compra de cada cliente.
    Analisa reten√ß√£o ao longo do tempo.
    """
    # Converter data para in√≠cio do m√™s
    df['cohort_month'] = df['date_purchase'].dt.to_period('M')
    
    # Identificar a primeira compra de cada cliente
    df_cohort = df.groupby('fk_contact')['cohort_month'].min().reset_index()
    df_cohort.columns = ['fk_contact', 'primeira_compra']
    
    # Mesclar com df original
    df = pd.merge(df, df_cohort, on='fk_contact', how='left')
    
    # Calcular per√≠odos desde a primeira compra
    df['periods'] = (df['cohort_month'].astype(str).astype('period[M]') - 
                    df['primeira_compra'].astype(str).astype('period[M]')).apply(lambda x: int(x))
    
    # Criar matriz de cohort
    cohort_data = df.groupby(['primeira_compra', 'periods'])['nk_ota_localizer_id'].nunique().reset_index()
    cohort_matrix = cohort_data.pivot_table(index='primeira_compra', 
                                          columns='periods', 
                                          values='nk_ota_localizer_id')
    
    # Calcular tamanho de cada cohort (clientes em per√≠odo 0)
    cohort_sizes = cohort_matrix[0]
    
    # Calcular taxas de reten√ß√£o
    retention_matrix = cohort_matrix.divide(cohort_sizes, axis=0) * 100
    
    return retention_matrix

def main():
    # Aplicar estilo personalizado
    st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        font-weight: 700;
        color: #1E3A8A;
        margin-bottom: 0.5rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #64748B;
        margin-bottom: 1.5rem;
    }
    .sistema-card {
        background-color: #F1F5F9;
        padding: 1.5rem;
        border-radius: 0.5rem;
        border-left: 5px solid #3B82F6;
        margin-bottom: 1rem;
    }
    .feature-icon {
        font-size: 2rem;
        margin-bottom: 0.5rem;
    }
    .feature-title {
        font-size: 1.2rem;
        font-weight: 600;
        color: #1E40AF;
        margin-bottom: 0.5rem;
    }
    .feature-description {
        color: #4B5563;
        font-size: 0.9rem;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Header principal
    st.markdown('<div class="main-header">üöå InfiniteBus</div>', unsafe_allow_html=True)
    st.markdown('<div class="sub-header">Sistema Inteligente de Previs√£o de Recompra</div>', unsafe_allow_html=True)
    
    # Descri√ß√£o do sistema em um card
    with st.container():
        st.markdown("""
        <div class="sistema-card">
            <h3>Vis√£o Geral da Solu√ß√£o</h3>
            <p>O InfiniteBus √© um sistema inteligente e unificado que utiliza Machine Learning para prever a pr√≥xima compra 
            de um cliente da ClickBus. Para alcan√ßar uma previs√£o completa e acion√°vel, o sistema analisa o comportamento 
            do cliente sob tr√™s perspectivas interdependentes, fornecendo um fluxo cont√≠nuo de insights para otimizar as vendas.</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Features do InfiniteBus
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div style="padding: 1.2rem; text-align: center; background-color: #EFF6FF; border-radius: 0.5rem; height: 100%;">
            <div class="feature-icon">üë•</div>
            <div class="feature-title">Mapeamento Comportamental</div>
            <div class="feature-description">Cria√ß√£o de perfis din√¢micos que consideram o hist√≥rico completo do cliente, 
            afinidades e prefer√™ncias, indo al√©m do RFM tradicional.</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div style="padding: 1.2rem; text-align: center; background-color: #EFF6FF; border-radius: 0.5rem; height: 100%;">
            <div class="feature-icon">‚è±Ô∏è</div>
            <div class="feature-title">Proje√ß√£o de Ciclo de Compra</div>
            <div class="feature-description">Estimativa da janela temporal mais prov√°vel para a pr√≥xima compra, baseada no 
            perfil comportamental individual e padr√µes sazonais.</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div style="padding: 1.2rem; text-align: center; background-color: #EFF6FF; border-radius: 0.5rem; height: 100%;">
            <div class="feature-icon">üó∫Ô∏è</div>
            <div class="feature-title">Identifica√ß√£o do Destino</div>
            <div class="feature-description">Sugest√£o do trecho com maior probabilidade de ser escolhido, analisando hist√≥rico 
            do cliente, comportamento de clientes similares e tend√™ncias de mercado.</div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("<br>", unsafe_allow_html=True)
    
    # Carregar dados
    if not os.path.exists(FILEPATH):
        st.error(f"Arquivo '{FILEPATH}' n√£o encontrado na pasta do projeto.")
        return
    
    df = load_and_preprocess_data(FILEPATH)
    if df is not None:
        # Buscar coluna de tickets de forma tolerante
        tickets_col = find_column(df, ["total_tickets_quantity_sucess", "total_tickets_quantity_success", "tickets", "qtd_passagens"])
        if not tickets_col:
            st.error("Coluna de quantidade de passagens n√£o encontrada. Verifique o nome no arquivo.")
            return
            
        # Menu Principal com Tabs
        tab1, tab2, tab3 = st.tabs([
            "üîç An√°lise de Comportamento", 
            "‚è±Ô∏è Previs√£o de Timing", 
            "üó∫Ô∏è Recomenda√ß√£o de Destinos"
        ])
        
        with tab1:
            parte1_analise(df, tickets_col)
        
        with tab2:
            parte2_analise(df)
        
        with tab3:
            parte3_analise(df)

if __name__ == "__main__":
    main() 